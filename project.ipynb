{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow==10.3.0\n",
      "  Downloading pillow-10.3.0-cp312-cp312-win_amd64.whl.metadata (9.4 kB)\n",
      "Downloading pillow-10.3.0-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 16.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.2.1\n",
      "    Uninstalling pillow-11.2.1:\n",
      "      Successfully uninstalled pillow-11.2.1\n",
      "Successfully installed pillow-10.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\mikae\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pillow==10.3.0\n",
    "%pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\~%mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\~0mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.2.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.2.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install toxigen datasets -q\n",
    "!pip install evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_sc_weight_BERT' from 'sc_weight_BERT_model' (c:\\Documents\\EPFL\\Cours\\MA2\\Deep learning\\project\\deep_learning2025\\sc_weight_BERT_model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloading_dataset_toxigen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_toxigen, post_process_toxigen\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhatebert_model_for_docker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_hatebert, tokenize_function, train_epoch_hatebert, evaluate_hatebert, evaluate_hatebert_with_bias\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msc_weight_BERT_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_sc_weight_BERT\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_sc_weight_BERT' from 'sc_weight_BERT_model' (c:\\Documents\\EPFL\\Cours\\MA2\\Deep learning\\project\\deep_learning2025\\sc_weight_BERT_model.py)"
     ]
    }
   ],
   "source": [
    "# If you see \"ImportError: numpy.core.multiarray failed to import\", \n",
    "# restart the kernel after running cell 0 to reload numpy.\n",
    "# Cell 0 reinstalls numpy, so a restart is required before running this cell.\n",
    "# !!! IMPORTANT: After running cell 0, restart the Jupyter kernel before running this cell !!!\n",
    "\n",
    "# !!! If you have not restarted the kernel after running cell 0, please do so now !!!\n",
    "# Otherwise, you may encounter ImportError related to numpy.\n",
    "\n",
    "from loading_dataset_toxigen import load_toxigen, post_process_toxigen\n",
    "from hatebert_model_for_docker import load_hatebert, tokenize_function, train_epoch_hatebert, evaluate_hatebert, evaluate_hatebert_with_bias\n",
    "from sc_weight_BERT_model import load_sc_weight_BERT\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hateXplain_dataset import HateXplainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxigen = load_toxigen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text', 'target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing', 'predicted_group', 'stereotyping', 'intent', 'toxicity_ai', 'toxicity_human', 'predicted_author', 'actual_method', 'labels'],\n",
      "        num_rows: 940\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text', 'target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing', 'predicted_group', 'stereotyping', 'intent', 'toxicity_ai', 'toxicity_human', 'predicted_author', 'actual_method', 'labels'],\n",
      "        num_rows: 8960\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(toxigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the class\n",
    "hatexplain = HateXplainDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hateXplain_dataset:Attempting to load HateXplain dataset...\n",
      "INFO:hateXplain_dataset:Processed 15383 examples from train split\n",
      "INFO:hateXplain_dataset:Processed 1922 examples from validation split\n",
      "INFO:hateXplain_dataset:Processed 1924 examples from test split\n",
      "INFO:hateXplain_dataset:Dataset loaded successfully\n",
      "INFO:hateXplain_dataset:Available splits: ['train', 'validation', 'test']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels', 'target_group'],\n",
      "        num_rows: 15383\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels', 'target_group'],\n",
      "        num_rows: 1922\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'labels', 'target_group'],\n",
      "        num_rows: 1924\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (this will also process the labels)\n",
    "dataset = hatexplain.load_dataset()\n",
    "\n",
    "# Print the dataset (this prints the HuggingFace DatasetDict object)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      "==================================================\n",
      "\n",
      "TRAIN Split Statistics:\n",
      "------------------------------\n",
      "Total examples: 15383\n",
      "\n",
      "Label Distribution:\n",
      "Hate Speech: 6251 (40.64%)\n",
      "Normal/Offensive: 9132 (59.36%)\n",
      "\n",
      "Target Group Distribution:\n",
      "None: 5509 (35.81%)\n",
      "African: 2335 (15.18%)\n",
      "Homosexual: 1161 (7.55%)\n",
      "Islam: 1156 (7.51%)\n",
      "Jewish: 1011 (6.57%)\n",
      "Women: 898 (5.84%)\n",
      "Other: 883 (5.74%)\n",
      "Arab: 603 (3.92%)\n",
      "Refugee: 529 (3.44%)\n",
      "Caucasian: 386 (2.51%)\n",
      "Asian: 269 (1.75%)\n",
      "Men: 236 (1.53%)\n",
      "Hispanic: 187 (1.22%)\n",
      "Disability: 53 (0.34%)\n",
      "Christian: 52 (0.34%)\n",
      "Heterosexual: 31 (0.20%)\n",
      "Minority: 24 (0.16%)\n",
      "Economic: 23 (0.15%)\n",
      "Indian: 15 (0.10%)\n",
      "Hindu: 11 (0.07%)\n",
      "none: 7 (0.05%)\n",
      "Indigenous: 2 (0.01%)\n",
      "Bisexual: 1 (0.01%)\n",
      "Buddhism: 1 (0.01%)\n",
      "\n",
      "Text Length Statistics:\n",
      "Average length: 23.47 words\n",
      "Maximum length: 165 words\n",
      "Minimum length: 2 words\n",
      "\n",
      "Hate Speech Distribution by Target Group:\n",
      "None: 4410 hate speech examples (80.05% of this target)\n",
      "Other: 253 hate speech examples (28.65% of this target)\n",
      "Homosexual: 238 hate speech examples (20.50% of this target)\n",
      "Islam: 228 hate speech examples (19.72% of this target)\n",
      "Refugee: 227 hate speech examples (42.91% of this target)\n",
      "African: 210 hate speech examples (8.99% of this target)\n",
      "Women: 187 hate speech examples (20.82% of this target)\n",
      "Men: 127 hate speech examples (53.81% of this target)\n",
      "Caucasian: 126 hate speech examples (32.64% of this target)\n",
      "Jewish: 72 hate speech examples (7.12% of this target)\n",
      "Asian: 63 hate speech examples (23.42% of this target)\n",
      "Arab: 58 hate speech examples (9.62% of this target)\n",
      "Christian: 19 hate speech examples (36.54% of this target)\n",
      "Hispanic: 12 hate speech examples (6.42% of this target)\n",
      "Disability: 6 hate speech examples (11.32% of this target)\n",
      "Heterosexual: 4 hate speech examples (12.90% of this target)\n",
      "Hindu: 3 hate speech examples (27.27% of this target)\n",
      "Minority: 3 hate speech examples (12.50% of this target)\n",
      "Economic: 3 hate speech examples (13.04% of this target)\n",
      "none: 2 hate speech examples (28.57% of this target)\n",
      "\n",
      "VALIDATION Split Statistics:\n",
      "------------------------------\n",
      "Total examples: 1922\n",
      "\n",
      "Label Distribution:\n",
      "Hate Speech: 781 (40.63%)\n",
      "Normal/Offensive: 1141 (59.37%)\n",
      "\n",
      "Target Group Distribution:\n",
      "None: 710 (36.94%)\n",
      "African: 283 (14.72%)\n",
      "Islam: 144 (7.49%)\n",
      "Homosexual: 141 (7.34%)\n",
      "Jewish: 135 (7.02%)\n",
      "Other: 119 (6.19%)\n",
      "Women: 107 (5.57%)\n",
      "Arab: 71 (3.69%)\n",
      "Refugee: 62 (3.23%)\n",
      "Caucasian: 46 (2.39%)\n",
      "Asian: 32 (1.66%)\n",
      "Men: 27 (1.40%)\n",
      "Hispanic: 23 (1.20%)\n",
      "Heterosexual: 6 (0.31%)\n",
      "Disability: 5 (0.26%)\n",
      "Minority: 4 (0.21%)\n",
      "Economic: 3 (0.16%)\n",
      "Indian: 2 (0.10%)\n",
      "Christian: 1 (0.05%)\n",
      "Nonreligious: 1 (0.05%)\n",
      "\n",
      "Text Length Statistics:\n",
      "Average length: 23.46 words\n",
      "Maximum length: 70 words\n",
      "Minimum length: 2 words\n",
      "\n",
      "Hate Speech Distribution by Target Group:\n",
      "None: 559 hate speech examples (78.73% of this target)\n",
      "Other: 34 hate speech examples (28.57% of this target)\n",
      "Homosexual: 28 hate speech examples (19.86% of this target)\n",
      "Refugee: 28 hate speech examples (45.16% of this target)\n",
      "Women: 24 hate speech examples (22.43% of this target)\n",
      "Islam: 23 hate speech examples (15.97% of this target)\n",
      "African: 22 hate speech examples (7.77% of this target)\n",
      "Caucasian: 17 hate speech examples (36.96% of this target)\n",
      "Men: 16 hate speech examples (59.26% of this target)\n",
      "Jewish: 11 hate speech examples (8.15% of this target)\n",
      "Asian: 9 hate speech examples (28.12% of this target)\n",
      "Arab: 6 hate speech examples (8.45% of this target)\n",
      "Heterosexual: 2 hate speech examples (33.33% of this target)\n",
      "Disability: 1 hate speech examples (20.00% of this target)\n",
      "Hispanic: 1 hate speech examples (4.35% of this target)\n",
      "\n",
      "TEST Split Statistics:\n",
      "------------------------------\n",
      "Total examples: 1924\n",
      "\n",
      "Label Distribution:\n",
      "Hate Speech: 782 (40.64%)\n",
      "Normal/Offensive: 1142 (59.36%)\n",
      "\n",
      "Target Group Distribution:\n",
      "None: 656 (34.10%)\n",
      "African: 299 (15.54%)\n",
      "Homosexual: 157 (8.16%)\n",
      "Other: 135 (7.02%)\n",
      "Islam: 134 (6.96%)\n",
      "Jewish: 128 (6.65%)\n",
      "Women: 110 (5.72%)\n",
      "Arab: 71 (3.69%)\n",
      "Refugee: 70 (3.64%)\n",
      "Caucasian: 61 (3.17%)\n",
      "Asian: 31 (1.61%)\n",
      "Men: 24 (1.25%)\n",
      "Hispanic: 23 (1.20%)\n",
      "Disability: 8 (0.42%)\n",
      "Christian: 6 (0.31%)\n",
      "Minority: 3 (0.16%)\n",
      "Economic: 3 (0.16%)\n",
      "Indian: 2 (0.10%)\n",
      "Heterosexual: 2 (0.10%)\n",
      "Indigenous: 1 (0.05%)\n",
      "\n",
      "Text Length Statistics:\n",
      "Average length: 23.14 words\n",
      "Maximum length: 55 words\n",
      "Minimum length: 3 words\n",
      "\n",
      "Hate Speech Distribution by Target Group:\n",
      "None: 524 hate speech examples (79.88% of this target)\n",
      "Other: 34 hate speech examples (25.19% of this target)\n",
      "African: 34 hate speech examples (11.37% of this target)\n",
      "Homosexual: 32 hate speech examples (20.38% of this target)\n",
      "Refugee: 31 hate speech examples (44.29% of this target)\n",
      "Caucasian: 27 hate speech examples (44.26% of this target)\n",
      "Women: 21 hate speech examples (19.09% of this target)\n",
      "Islam: 20 hate speech examples (14.93% of this target)\n",
      "Men: 19 hate speech examples (79.17% of this target)\n",
      "Jewish: 13 hate speech examples (10.16% of this target)\n",
      "Arab: 8 hate speech examples (11.27% of this target)\n",
      "Asian: 8 hate speech examples (25.81% of this target)\n",
      "Christian: 4 hate speech examples (66.67% of this target)\n",
      "Hispanic: 3 hate speech examples (13.04% of this target)\n",
      "Economic: 2 hate speech examples (66.67% of this target)\n",
      "Disability: 1 hate speech examples (12.50% of this target)\n",
      "Minority: 1 hate speech examples (33.33% of this target)\n"
     ]
    }
   ],
   "source": [
    "# If you want to print statistics (using your class's method):\n",
    "# Note: The print_dataset_statistics method expects self._processed_dataset to be set.\n",
    "# You can set it manually after loading:\n",
    "hatexplain._processed_dataset = dataset\n",
    "hatexplain.print_dataset_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sc_weight_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_HateXplain_dataset = dataset[\"train\"]\n",
    "eval_HateXplain_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels', 'target_group'],\n",
      "    num_rows: 15383\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_HateXplain_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HateXplainDataset.post_process_HateXplain() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenzied_HateXplain \u001b[38;5;241m=\u001b[39m hatexplain\u001b[38;5;241m.\u001b[39mpost_process_HateXplain(dataset)\n",
      "\u001b[1;31mTypeError\u001b[0m: HateXplainDataset.post_process_HateXplain() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "tokenzied_HateXplain = hatexplain.post_process_HateXplain(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at GroNLP/hateBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model_hatebert = load_hatebert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " apply the function to all the elements in the dataset (individually or in batches)\n",
    " https://huggingface.co/docs/datasets/v1.11.0/package_reference/main_classes.html?highlight=dataset%20map#datasets.Dataset.map\n",
    " batch mode is very powerful. It allows you to speed up processing\n",
    " more info here: https://huggingface.co/docs/datasets/en/about_map_batch\n",
    "'''\n",
    "cache_files = {\n",
    "    \"test\": \".cache/datasets/toxigen/toxigen_test_tokenized.arrow\",\n",
    "    \"train\": \".cache/datasets/toxigen/toxigen_train_tokenized.arrow\"\n",
    "} #path to the local cache files, where the current computation from the following function will be stored. \n",
    "# Caching saves RAM when working with large datasets and saves time instead of doing transformations on the fly.\n",
    "tokenized_toxigen = toxigen.map(lambda x: tokenize_function(tokenizer, x, \"text\"), batched=True, cache_file_names=cache_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text', 'target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing', 'predicted_group', 'stereotyping', 'intent', 'toxicity_ai', 'toxicity_human', 'predicted_author', 'actual_method', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 940\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text', 'target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing', 'predicted_group', 'stereotyping', 'intent', 'toxicity_ai', 'toxicity_human', 'predicted_author', 'actual_method', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 8960\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_toxigen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_toxigen = post_process_toxigen(tokenized_toxigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing', 'predicted_group', 'stereotyping', 'intent', 'toxicity_ai', 'toxicity_human', 'predicted_author', 'actual_method', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 940\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing', 'predicted_group', 'stereotyping', 'intent', 'toxicity_ai', 'toxicity_human', 'predicted_author', 'actual_method', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 8960\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_toxigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a smaller subset of the dataset as previously shown to speed up the fine-tuning\n",
    "\n",
    "small_train_dataset = tokenized_toxigen[\"train\"].shuffle(seed=42).select(range(50))\n",
    "small_eval_dataset = tokenized_toxigen[\"test\"].shuffle(seed=42).select(range(50))\n",
    "\n",
    "train_dataset = tokenized_toxigen[\"train\"]\n",
    "eval_dataset = tokenized_toxigen[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataLoader for your training and test datasets so you can iterate over batches of data:\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
    "test_dataloader = DataLoader(small_eval_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HateBERT number of parameters:  109483778\n"
     ]
    }
   ],
   "source": [
    "print(\"HateBERT number of parameters: \", model_hatebert.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model_hatebert.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 2\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "# feel free to experiment with different num_warmup_steps\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=1, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_hatebert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [00:29<06:26, 29.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:53<05:17, 26.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [01:16<04:29, 24.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loss, train_metrics \u001b[38;5;241m=\u001b[39m train_epoch_hatebert(model_hatebert, num_epochs, train_dataloader, optimizer, lr_scheduler, device, num_training_steps)\n",
      "File \u001b[1;32mc:\\Documents\\EPFL\\Cours\\MA2\\Deep learning\\project\\deep_learning2025\\hatebert_model.py:106\u001b[0m, in \u001b[0;36mtrain_epoch_hatebert\u001b[1;34m(model, num_epochs, train_dataloader, optimizer, lr_scheduler, device, num_training_steps)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mc:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    650\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m _engine_run_backward(\n\u001b[0;32m    354\u001b[0m     tensors,\n\u001b[0;32m    355\u001b[0m     grad_tensors_,\n\u001b[0;32m    356\u001b[0m     retain_graph,\n\u001b[0;32m    357\u001b[0m     create_graph,\n\u001b[0;32m    358\u001b[0m     inputs,\n\u001b[0;32m    359\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    360\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    361\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, train_metrics = train_epoch_hatebert(model_hatebert, num_epochs, train_dataloader, optimizer, lr_scheduler, device, num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bade68b117de4334aa282787793b8dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:05<00:35,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:11<00:29,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:18<00:24,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [00:24<00:18,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:31<00:12,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [00:37<00:06,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:39<00:00,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_hatebert(model_hatebert, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n",
      "Batch type: <class 'dict'>\n",
      "Batch type: <class 'dict'>\n",
      "Batch type: <class 'dict'>\n",
      "Batch type: <class 'dict'>\n",
      "Batch type: <class 'dict'>\n",
      "Batch type: <class 'dict'>\n",
      "Overall Accuracy: 0.6400\n",
      "Accuracy for target group 'asian folks': 1.0000\n",
      "Number of samples in group 'asian folks': 1\n",
      "Confusion Matrix for 'asian folks':\n",
      "[[1]]\n",
      "\n",
      "Accuracy for target group 'black folks / african-americans': 0.5000\n",
      "Number of samples in group 'black folks / african-americans': 2\n",
      "Confusion Matrix for 'black folks / african-americans':\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "\n",
      "Accuracy for target group 'black/african-american folks': 0.2500\n",
      "Number of samples in group 'black/african-american folks': 4\n",
      "Confusion Matrix for 'black/african-american folks':\n",
      "[[1 0]\n",
      " [3 0]]\n",
      "\n",
      "Accuracy for target group 'chinese folks': 1.0000\n",
      "Number of samples in group 'chinese folks': 3\n",
      "Confusion Matrix for 'chinese folks':\n",
      "[[3]]\n",
      "\n",
      "Accuracy for target group 'folks with mental disabilities': 0.2500\n",
      "Number of samples in group 'folks with mental disabilities': 4\n",
      "Confusion Matrix for 'folks with mental disabilities':\n",
      "[[1 0]\n",
      " [3 0]]\n",
      "\n",
      "Accuracy for target group 'folks with physical disabilities': 0.8000\n",
      "Number of samples in group 'folks with physical disabilities': 5\n",
      "Confusion Matrix for 'folks with physical disabilities':\n",
      "[[4 0]\n",
      " [1 0]]\n",
      "\n",
      "Accuracy for target group 'jewish folks': 0.3333\n",
      "Number of samples in group 'jewish folks': 3\n",
      "Confusion Matrix for 'jewish folks':\n",
      "[[1 0]\n",
      " [2 0]]\n",
      "\n",
      "Accuracy for target group 'latino/hispanic folks': 1.0000\n",
      "Number of samples in group 'latino/hispanic folks': 3\n",
      "Confusion Matrix for 'latino/hispanic folks':\n",
      "[[3]]\n",
      "\n",
      "Accuracy for target group 'lgbtq+ folks': 0.5000\n",
      "Number of samples in group 'lgbtq+ folks': 6\n",
      "Confusion Matrix for 'lgbtq+ folks':\n",
      "[[3 0]\n",
      " [3 0]]\n",
      "\n",
      "Accuracy for target group 'mexican folks': 1.0000\n",
      "Number of samples in group 'mexican folks': 5\n",
      "Confusion Matrix for 'mexican folks':\n",
      "[[5]]\n",
      "\n",
      "Accuracy for target group 'middle eastern folks': 0.2500\n",
      "Number of samples in group 'middle eastern folks': 4\n",
      "Confusion Matrix for 'middle eastern folks':\n",
      "[[1 0]\n",
      " [3 0]]\n",
      "\n",
      "Accuracy for target group 'muslim folks': 0.7500\n",
      "Number of samples in group 'muslim folks': 4\n",
      "Confusion Matrix for 'muslim folks':\n",
      "[[3 0]\n",
      " [1 0]]\n",
      "\n",
      "Accuracy for target group 'native american folks': 1.0000\n",
      "Number of samples in group 'native american folks': 3\n",
      "Confusion Matrix for 'native american folks':\n",
      "[[3]]\n",
      "\n",
      "Accuracy for target group 'native american/indigenous folks': 1.0000\n",
      "Number of samples in group 'native american/indigenous folks': 1\n",
      "Confusion Matrix for 'native american/indigenous folks':\n",
      "[[1]]\n",
      "\n",
      "Accuracy for target group 'women': 0.5000\n",
      "Number of samples in group 'women': 2\n",
      "Confusion Matrix for 'women':\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mikae\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_accuracy, epoch_loss, epoch_metrics = evaluate_hatebert_with_bias(model_hatebert, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train_cycle(model, optimizer, criterion, metrics, train_loader, test_loader, n_epochs, device,\n",
    "                store_checkpoint_for_every_epoch, start_epoch=0):\n",
    "    train_loss_log,  test_loss_log = [], []\n",
    "    metrics_names = list(metrics.keys())\n",
    "    train_metrics_log = [[] for i in range(len(metrics))]\n",
    "    test_metrics_log = [[] for i in range(len(metrics))]\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        print(\"Epoch {0} of {1}\".format(epoch, n_epochs - 1))\n",
    "        train_loss, train_metrics = train_epoch_hatebert(model_hatebert, num_epochs, train_dataloader, optimizer, lr_scheduler, device, num_training_steps)(model, optimizer, criterion, metrics, train_loader, device)\n",
    "\n",
    "        test_loss, test_metrics = evaluate_hatebert_with_bias(model, criterion, metrics, test_loader, device)\n",
    "\n",
    "        train_loss_log.append(train_loss)\n",
    "        train_metrics_log = update_metrics_log(metrics_names, train_metrics_log, train_metrics)\n",
    "\n",
    "        test_loss_log.append(test_loss)\n",
    "        test_metrics_log = update_metrics_log(metrics_names, test_metrics_log, test_metrics)\n",
    "\n",
    "        plot_training(train_loss_log, test_loss_log, metrics_names, train_metrics_log, test_metrics_log)\n",
    "\n",
    "        save_checkpoint(model, optimizer, epoch, loss=train_loss, checkpoint_path = Path(RESULTS_DIR) / \"checkpoints/checkpoint.pth\",\n",
    "                        store_checkpoint_for_every_epoch=store_checkpoint_for_every_epoch)\n",
    "    return train_metrics_log, test_metrics_log\n",
    "\n",
    "\n",
    "saved_epoch, _ = load_checkpoint(model, optimizer, checkpoint_path = Path(RESULTS_DIR) / \"checkpoints/checkpoint.pth\")\n",
    "if saved_epoch == 0:\n",
    "    start_epoch = 0\n",
    "else:\n",
    "    start_epoch = saved_epoch + 1  #if the checkpoint from the epoch saved_epoch is stored, we want to start the training from the next epoch\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "N_EPOCHS = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "model_hatebert.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "\n",
    "train_metrics_log, test_metrics_log = train_cycle(model_hatebert, optimizer, criterion, metrics, train_loader, valid_loader,\n",
    "                                                  n_epochs=N_EPOCHS, device=device, store_checkpoint_for_every_epoch=False,\n",
    "                                                  start_epoch=start_epoch)\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
